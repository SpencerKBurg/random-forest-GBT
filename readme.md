# Random Forest and Gradient Boosted Trees

This is a project that I did for the UW Machine Learning program showing some of the benefits of random forests and gradient boosted trees by using a classification problem on a simple, overlapping, moon-shaped dataset. By comparing the model performance of various classifiers, ranging from simple linear model to ensemble tree-based models, the power of ensemble models is demonstrated. It also demonstrates the benefits of using cross validation for parameter tuning.
